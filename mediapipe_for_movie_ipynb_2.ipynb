{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuQfLvpuJkb0",
        "outputId": "748ca886-cff0-4d97-e51f-d572222d720f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title **set up**\n",
        "\n",
        "# install mediapipe\n",
        "!pip install mediapipe\n",
        "\n",
        "# clone github code\n",
        "!git clone https://github.com/cedro3/mediapipe.git\n",
        "%cd mediapipe/\n",
        "\n",
        "# initial setting\n",
        "import mediapipe as mp\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "# Initialize MediaPipe Holistic.\n",
        "holistic = mp_holistic.Holistic(\n",
        "    static_image_mode=True, min_detection_confidence=0.5)\n",
        "\n",
        "# Prepare DrawingSpec for drawing the face landmarks later.\n",
        "WHITE_COLOR = (224, 224, 224)\n",
        "BLACK_COLOR = (0, 0, 0)\n",
        "RED_COLOR = (0, 0, 255)\n",
        "GREEN_COLOR = (0, 128, 0)\n",
        "BLUE_COLOR = (255, 0, 0)\n",
        "mp_drawing = mp.solutions.drawing_utils \n",
        "drawing_face_spec = mp_drawing.DrawingSpec(color=WHITE_COLOR, thickness=1, circle_radius=1)\n",
        "drawing_pose_spec = mp_drawing.DrawingSpec(color=WHITE_COLOR, thickness=3, circle_radius=3)\n",
        "drawing_hand_spec = mp_drawing.DrawingSpec(color=WHITE_COLOR, thickness=3, circle_radius=3)\n",
        "drawing_dot_spec = mp_drawing.DrawingSpec(color=RED_COLOR, thickness=2, circle_radius=3)\n",
        "\n",
        "# define fuction\n",
        "!pip install function\n",
        "from function import *\n",
        "\n",
        "#諸々モジュール\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "!pip install function\n",
        "from function import *\n",
        "!pip install mecab-python3\n",
        "\n",
        "#画像読み込みのセットアップ\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.3.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mediapipe) (1.15.0)\n",
            "Installing collected packages: flatbuffers, mediapipe\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 23.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-23.1.4 mediapipe-0.9.0.1\n",
            "Cloning into 'mediapipe'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 162 (delta 62), reused 49 (delta 49), pack-reused 84\u001b[K\n",
            "Receiving objects: 100% (162/162), 2.40 MiB | 22.12 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/mediapipe\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: function in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: function in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.8/dist-packages (1.0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **video-to-frames**\n",
        "#@markdown upload video(mp4) with sound to movie/video folder\n",
        "\n",
        "#諸々モジュール\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "print( cv2.__version__ )\n",
        "\n",
        "#・Google Cloud SDKの認証\n",
        "#authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)\n",
        "\n",
        "#id = 'https://drive.google.com/file/d/1dPtsvCAnthoiSXNJDRESSiOjLJM9TcQV/view?usp=share_link'\n",
        "#video= drive.CreateFile({'id': id})\n",
        "\n",
        "video = 'ishihara.mp4' #@param {type:\"string\"}\n",
        "video_file = 'video/'+video\n",
        "image_dir='frames/'\n",
        "image_file='%s.jpg'\n",
        "\n",
        "def video_2_images(video_file= video_file,   # ビデオの指定\n",
        "                   image_dir='images/', \n",
        "                   image_file='%s.jpg'):     \n",
        "    # Initial setting\n",
        "    i = 0\n",
        "    interval = 1\n",
        "    length = 3000  # 最大フレーム数\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)  # fps取得\n",
        " \n",
        "    while(cap.isOpened()):\n",
        "        flag, frame = cap.read()  \n",
        "        if flag == False:  \n",
        "                break\n",
        "        if i == length*interval:\n",
        "                break\n",
        "        if i % interval == 0:    \n",
        "           cv2.imwrite(image_dir+image_file % str(int(i/interval)).zfill(6), frame)\n",
        "        i += 1 \n",
        "    cap.release()\n",
        "    return fps, i, interval\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        " \n",
        "def reset_folder(path):\n",
        "    if os.path.isdir(path):\n",
        "      shutil.rmtree(path)\n",
        "    os.makedirs(path,exist_ok=True)\n",
        " \n",
        "\n",
        "# video_2_images\n",
        "reset_folder('frames')\n",
        "fps, i, interval = video_2_images(video_file, image_dir, image_file)\n",
        " \n",
        "# display strat frame\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('frames/000000.jpg')\n",
        "cv2_imshow(img)\n",
        " \n",
        "# display parameter\n",
        "print('fps = ', fps)\n",
        "print('frames = ', i)\n",
        "print('interval = ', interval)"
      ],
      "metadata": {
        "id": "n-B0nVeD_5I7",
        "outputId": "f6a4a734-635b-4559-8519-e039040cfb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n",
            "4.6.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b74413f78c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frames/000000.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# display parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs2IYWOGtCGj"
      },
      "source": [
        "#@title **MediaPipe from frames to images**\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm ###\n",
        "\n",
        "# reset images folder\n",
        "reset_folder('images')\n",
        "\n",
        "# image file names to files in list format\n",
        "files=[]\n",
        "for name in sorted(glob.glob('./frames/*.jpg')):\n",
        "    files.append(name)\n",
        "\n",
        "# Read images with OpenCV.\n",
        "images = {name: cv2.imread(name) for name in files}\n",
        "\n",
        "#for name, image in images.items():\n",
        "for name, image in tqdm(images.items()):  \n",
        "  # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
        "  results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  # Draw pose landmarks.\n",
        "  annotated_image = image.copy()\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image,\n",
        "      landmark_list=results.left_hand_landmarks,\n",
        "      connections=mp_holistic.HAND_CONNECTIONS,\n",
        "      landmark_drawing_spec=drawing_dot_spec,\n",
        "      connection_drawing_spec=drawing_hand_spec)\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image,\n",
        "      landmark_list=results.right_hand_landmarks,\n",
        "      connections=mp_holistic.HAND_CONNECTIONS,\n",
        "      landmark_drawing_spec=drawing_dot_spec,\n",
        "      connection_drawing_spec=drawing_hand_spec)\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image, \n",
        "      landmark_list=results.face_landmarks, \n",
        "      connections=mp_holistic.FACEMESH_TESSELATION,  ###\n",
        "      landmark_drawing_spec=drawing_face_spec,\n",
        "      connection_drawing_spec=drawing_face_spec)\n",
        "  mp_drawing.draw_landmarks(\n",
        "      image=annotated_image, \n",
        "      landmark_list=results.pose_landmarks, \n",
        "      connections=mp_holistic.POSE_CONNECTIONS,\n",
        "      landmark_drawing_spec=drawing_pose_spec,\n",
        "      connection_drawing_spec=drawing_pose_spec)\n",
        "  \n",
        "  save_name = 'images/'+os.path.basename(name) ###\n",
        "  cv2.imwrite(save_name, annotated_image)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **make movie from images**\n",
        "#@markdown　check with_sound if the video has sound\n",
        "with_sound = True #@param {type:\"boolean\"}\n",
        "fps_r = fps/interval\n",
        "\n",
        "print('making movie...')\n",
        "if with_sound ==  True:  \n",
        "  ! ffmpeg -y -r $fps_r -i images/%6d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error out.mp4\n",
        "  # audio extraction/addition\n",
        "  print('preparation for sound...')\n",
        "  ! ffmpeg -y -i $video_file -loglevel error sound.mp3\n",
        "  ! ffmpeg -y -i out.mp4 -i sound.mp3 -loglevel error output.mp4\n",
        "else:\n",
        "  ! ffmpeg -y -r $fps_r -i images/%6d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error output.mp4\n",
        "\n",
        "display_mp4('output.mp4')"
      ],
      "metadata": {
        "id": "Ym_QZlqrCM0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **download movie** (chrome)\n",
        "from google.colab import files\n",
        "files.download('output.mp4')"
      ],
      "metadata": {
        "id": "3PDnNaxhSHe4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}